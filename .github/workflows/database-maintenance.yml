# æ•°æ®åº“ç»´æŠ¤å·¥ä½œæµï¼ˆé»˜è®¤ç¦ç”¨ï¼‰
name: Database Maintenance

on:
  # é»˜è®¤ç¦ç”¨è‡ªåŠ¨è§¦å‘ï¼Œéœ€è¦æ‰‹åŠ¨å¯ç”¨
  # schedule:
  #   # æ¯å¤©å‡Œæ™¨ 3:00 UTC æ‰§è¡Œæ•°æ®åº“ç»´æŠ¤
  #   - cron: "0 3 * * *"
  #   # æ¯å‘¨æ—¥å‡Œæ™¨ 1:00 UTC æ‰§è¡Œæ·±åº¦ç»´æŠ¤
  #   - cron: "0 1 * * 0"
  workflow_dispatch:
    inputs:
      enable_workflow:
        description: "å¯ç”¨å·¥ä½œæµï¼ˆé»˜è®¤ç¦ç”¨ï¼‰"
        required: true
        default: false
        type: boolean
      maintenance_type:
        description: "ç»´æŠ¤ç±»å‹"
        required: true
        default: "routine"
        type: choice
        options:
          - routine
          - deep
          - emergency
          - vacuum
          - analyze
          - reindex
      environment:
        description: "ç›®æ ‡ç¯å¢ƒ"
        required: true
        default: "staging"
        type: choice
        options:
          - staging
          - production
      skip_backup:
        description: "è·³è¿‡å¤‡ä»½"
        required: false
        default: false
        type: boolean

env:
  MAINTENANCE_TYPE: ${{ inputs.maintenance_type || (github.event.schedule == '0 1 * * 0' && 'deep' || 'routine') }}
  ENVIRONMENT: ${{ inputs.environment || 'staging' }}
  SKIP_BACKUP: ${{ inputs.skip_backup || 'false' }}

jobs:
  # ===== é¢„æ£€æŸ¥ =====
  pre-check:
    name: ç»´æŠ¤å‰æ£€æŸ¥
    runs-on: ubuntu-latest
    outputs:
      can-proceed: ${{ steps.check.outputs.can-proceed }}
      db-size: ${{ steps.check.outputs.db-size }}
      active-connections: ${{ steps.check.outputs.active-connections }}

    steps:
      - name: æ£€å‡ºä»£ç 
        uses: actions/checkout@v4

      - name: è®¾ç½®ç¯å¢ƒå˜é‡
        run: |
          if [ "$ENVIRONMENT" = "production" ]; then
            echo "DB_HOST=${{ secrets.PROD_DB_HOST }}" >> $GITHUB_ENV
            echo "DB_PORT=${{ secrets.PROD_DB_PORT }}" >> $GITHUB_ENV
            echo "DB_USER=${{ secrets.PROD_DB_USER }}" >> $GITHUB_ENV
            echo "DB_PASSWORD=${{ secrets.PROD_DB_PASSWORD }}" >> $GITHUB_ENV
            echo "DB_NAME=${{ secrets.PROD_DB_NAME }}" >> $GITHUB_ENV
          else
            echo "DB_HOST=${{ secrets.STAGING_DB_HOST }}" >> $GITHUB_ENV
            echo "DB_PORT=${{ secrets.STAGING_DB_PORT }}" >> $GITHUB_ENV
            echo "DB_USER=${{ secrets.STAGING_DB_USER }}" >> $GITHUB_ENV
            echo "DB_PASSWORD=${{ secrets.STAGING_DB_PASSWORD }}" >> $GITHUB_ENV
            echo "DB_NAME=${{ secrets.STAGING_DB_NAME }}" >> $GITHUB_ENV
          fi

      - name: å®‰è£…PostgreSQLå®¢æˆ·ç«¯
        run: |
          sudo apt-get update
          sudo apt-get install -y postgresql-client

      - name: æ•°æ®åº“è¿æ¥æ£€æŸ¥
        id: check
        env:
          PGPASSWORD: ${{ env.DB_PASSWORD }}
        run: |
          echo "æ£€æŸ¥æ•°æ®åº“è¿æ¥..."

          # æµ‹è¯•æ•°æ®åº“è¿æ¥
          if psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -c "SELECT 1;" > /dev/null 2>&1; then
            echo "âœ… æ•°æ®åº“è¿æ¥æ­£å¸¸"
            CAN_PROCEED="true"
          else
            echo "âŒ æ•°æ®åº“è¿æ¥å¤±è´¥"
            CAN_PROCEED="false"
          fi

          if [ "$CAN_PROCEED" = "true" ]; then
            # è·å–æ•°æ®åº“å¤§å°
            DB_SIZE=$(psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -t -c "SELECT pg_size_pretty(pg_database_size('$DB_NAME'));" | tr -d ' ')
            echo "æ•°æ®åº“å¤§å°: $DB_SIZE"
            
            # è·å–æ´»è·ƒè¿æ¥æ•°
            ACTIVE_CONNECTIONS=$(psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -t -c "SELECT count(*) FROM pg_stat_activity WHERE state = 'active';" | tr -d ' ')
            echo "æ´»è·ƒè¿æ¥æ•°: $ACTIVE_CONNECTIONS"
            
            # æ£€æŸ¥æ˜¯å¦æœ‰é•¿æ—¶é—´è¿è¡Œçš„æŸ¥è¯¢
            LONG_QUERIES=$(psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -t -c "SELECT count(*) FROM pg_stat_activity WHERE state = 'active' AND now() - query_start > interval '5 minutes';" | tr -d ' ')
            
            if [ "$LONG_QUERIES" -gt 0 ]; then
              echo "âš ï¸ å‘ç° $LONG_QUERIES ä¸ªé•¿æ—¶é—´è¿è¡Œçš„æŸ¥è¯¢"
              if [ "$ENVIRONMENT" = "production" ] && [ "$MAINTENANCE_TYPE" != "emergency" ]; then
                echo "âŒ ç”Ÿäº§ç¯å¢ƒå­˜åœ¨é•¿æŸ¥è¯¢ï¼Œå»ºè®®ç¨åé‡è¯•"
                CAN_PROCEED="false"
              fi
            fi
            
            # æ£€æŸ¥ç£ç›˜ç©ºé—´
            DISK_USAGE=$(psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -t -c "SELECT round(100.0 * (1 - (pg_database_size('$DB_NAME')::float / (1024*1024*1024*100)))) as disk_usage_percent;" | tr -d ' ' 2>/dev/null || echo "0")
            
            echo "ç£ç›˜ä½¿ç”¨ç‡ä¼°ç®—: $DISK_USAGE%"
            
            echo "can-proceed=$CAN_PROCEED" >> $GITHUB_OUTPUT
            echo "db-size=$DB_SIZE" >> $GITHUB_OUTPUT
            echo "active-connections=$ACTIVE_CONNECTIONS" >> $GITHUB_OUTPUT
          else
            echo "can-proceed=false" >> $GITHUB_OUTPUT
          fi

      - name: ç”Ÿäº§ç¯å¢ƒé¢å¤–æ£€æŸ¥
        if: env.ENVIRONMENT == 'production'
        env:
          PGPASSWORD: ${{ env.DB_PASSWORD }}
        run: |
          echo "æ‰§è¡Œç”Ÿäº§ç¯å¢ƒé¢å¤–æ£€æŸ¥..."

          # æ£€æŸ¥å¤åˆ¶çŠ¶æ€ï¼ˆå¦‚æœæœ‰ï¼‰
          REPLICATION_STATUS=$(psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -t -c "SELECT count(*) FROM pg_stat_replication;" | tr -d ' ' 2>/dev/null || echo "0")
          echo "å¤åˆ¶è¿æ¥æ•°: $REPLICATION_STATUS"

          # æ£€æŸ¥é”ç­‰å¾…
          LOCK_WAITS=$(psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -t -c "SELECT count(*) FROM pg_locks WHERE NOT granted;" | tr -d ' ')
          echo "é”ç­‰å¾…æ•°: $LOCK_WAITS"

          if [ "$LOCK_WAITS" -gt 5 ]; then
            echo "âš ï¸ å‘ç°è¾ƒå¤šé”ç­‰å¾…ï¼Œå»ºè®®ç¨åæ‰§è¡Œç»´æŠ¤"
          fi

  # ===== ç»´æŠ¤å‰å¤‡ä»½ =====
  pre-maintenance-backup:
    name: ç»´æŠ¤å‰å¤‡ä»½
    runs-on: ubuntu-latest
    needs: pre-check
    if: needs.pre-check.outputs.can-proceed == 'true' && env.SKIP_BACKUP != 'true'
    outputs:
      backup-file: ${{ steps.backup.outputs.backup-file }}

    steps:
      - name: æ£€å‡ºä»£ç 
        uses: actions/checkout@v4

      - name: è®¾ç½®ç¯å¢ƒå˜é‡
        run: |
          if [ "$ENVIRONMENT" = "production" ]; then
            echo "DB_HOST=${{ secrets.PROD_DB_HOST }}" >> $GITHUB_ENV
            echo "DB_PORT=${{ secrets.PROD_DB_PORT }}" >> $GITHUB_ENV
            echo "DB_USER=${{ secrets.PROD_DB_USER }}" >> $GITHUB_ENV
            echo "DB_PASSWORD=${{ secrets.PROD_DB_PASSWORD }}" >> $GITHUB_ENV
            echo "DB_NAME=${{ secrets.PROD_DB_NAME }}" >> $GITHUB_ENV
          else
            echo "DB_HOST=${{ secrets.STAGING_DB_HOST }}" >> $GITHUB_ENV
            echo "DB_PORT=${{ secrets.STAGING_DB_PORT }}" >> $GITHUB_ENV
            echo "DB_USER=${{ secrets.STAGING_DB_USER }}" >> $GITHUB_ENV
            echo "DB_PASSWORD=${{ secrets.STAGING_DB_PASSWORD }}" >> $GITHUB_ENV
            echo "DB_NAME=${{ secrets.STAGING_DB_NAME }}" >> $GITHUB_ENV
          fi

      - name: å®‰è£…PostgreSQLå®¢æˆ·ç«¯
        run: |
          sudo apt-get update
          sudo apt-get install -y postgresql-client

      - name: åˆ›å»ºç»´æŠ¤å‰å¤‡ä»½
        id: backup
        env:
          PGPASSWORD: ${{ env.DB_PASSWORD }}
        run: |
          TIMESTAMP=$(date +%Y%m%d_%H%M%S)
          BACKUP_FILE="maintenance-backup-${ENVIRONMENT}-${TIMESTAMP}.sql.gz"

          echo "åˆ›å»ºç»´æŠ¤å‰å¤‡ä»½: $BACKUP_FILE"

          # åˆ›å»ºå¤‡ä»½
          pg_dump -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" --verbose | gzip > "$BACKUP_FILE"

          # éªŒè¯å¤‡ä»½æ–‡ä»¶
          if [ -f "$BACKUP_FILE" ]; then
            BACKUP_SIZE=$(stat -c%s "$BACKUP_FILE")
            echo "å¤‡ä»½æ–‡ä»¶å¤§å°: $BACKUP_SIZE bytes"
            
            if [ $BACKUP_SIZE -lt 1000 ]; then
              echo "âŒ å¤‡ä»½æ–‡ä»¶å¤ªå°ï¼Œå¯èƒ½å¤‡ä»½å¤±è´¥"
              exit 1
            fi
            
            echo "âœ… å¤‡ä»½åˆ›å»ºæˆåŠŸ"
            echo "backup-file=$BACKUP_FILE" >> $GITHUB_OUTPUT
          else
            echo "âŒ å¤‡ä»½æ–‡ä»¶æœªåˆ›å»º"
            exit 1
          fi

      - name: ä¸Šä¼ å¤‡ä»½æ–‡ä»¶
        uses: actions/upload-artifact@v3
        with:
          name: maintenance-backup-${{ env.ENVIRONMENT }}
          path: ${{ steps.backup.outputs.backup-file }}
          retention-days: 7

  # ===== å¸¸è§„ç»´æŠ¤ =====
  routine-maintenance:
    name: å¸¸è§„ç»´æŠ¤
    runs-on: ubuntu-latest
    needs: [pre-check, pre-maintenance-backup]
    if: always() && needs.pre-check.outputs.can-proceed == 'true' && (env.MAINTENANCE_TYPE == 'routine' || env.MAINTENANCE_TYPE == 'emergency')

    steps:
      - name: è®¾ç½®ç¯å¢ƒå˜é‡
        run: |
          if [ "$ENVIRONMENT" = "production" ]; then
            echo "DB_HOST=${{ secrets.PROD_DB_HOST }}" >> $GITHUB_ENV
            echo "DB_PORT=${{ secrets.PROD_DB_PORT }}" >> $GITHUB_ENV
            echo "DB_USER=${{ secrets.PROD_DB_USER }}" >> $GITHUB_ENV
            echo "DB_PASSWORD=${{ secrets.PROD_DB_PASSWORD }}" >> $GITHUB_ENV
            echo "DB_NAME=${{ secrets.PROD_DB_NAME }}" >> $GITHUB_ENV
          else
            echo "DB_HOST=${{ secrets.STAGING_DB_HOST }}" >> $GITHUB_ENV
            echo "DB_PORT=${{ secrets.STAGING_DB_PORT }}" >> $GITHUB_ENV
            echo "DB_USER=${{ secrets.STAGING_DB_USER }}" >> $GITHUB_ENV
            echo "DB_PASSWORD=${{ secrets.STAGING_DB_PASSWORD }}" >> $GITHUB_ENV
            echo "DB_NAME=${{ secrets.STAGING_DB_NAME }}" >> $GITHUB_ENV
          fi

      - name: å®‰è£…PostgreSQLå®¢æˆ·ç«¯
        run: |
          sudo apt-get update
          sudo apt-get install -y postgresql-client

      - name: ç»Ÿè®¡ä¿¡æ¯æ›´æ–°
        env:
          PGPASSWORD: ${{ env.DB_PASSWORD }}
        run: |
          echo "æ›´æ–°è¡¨ç»Ÿè®¡ä¿¡æ¯..."

          # æ›´æ–°æ‰€æœ‰è¡¨çš„ç»Ÿè®¡ä¿¡æ¯
          psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -c "ANALYZE;"

          echo "âœ… ç»Ÿè®¡ä¿¡æ¯æ›´æ–°å®Œæˆ"

      - name: æ¸…ç†è¿‡æœŸæ•°æ®
        env:
          PGPASSWORD: ${{ env.DB_PASSWORD }}
        run: |
          echo "æ¸…ç†è¿‡æœŸæ•°æ®..."

          # æ¸…ç†è¿‡æœŸçš„ä¼šè¯è®°å½•ï¼ˆä¿ç•™30å¤©ï¼‰
          DELETED_SESSIONS=$(psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -t -c "DELETE FROM user_sessions WHERE created_at < NOW() - INTERVAL '30 days'; SELECT ROW_COUNT();" | tr -d ' ' 2>/dev/null || echo "0")
          echo "æ¸…ç†è¿‡æœŸä¼šè¯: $DELETED_SESSIONS æ¡"

          # æ¸…ç†è¿‡æœŸçš„æ—¥å¿—è®°å½•ï¼ˆä¿ç•™90å¤©ï¼‰
          DELETED_LOGS=$(psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -t -c "DELETE FROM logs WHERE created_at < NOW() - INTERVAL '90 days' RETURNING 1;" | wc -l 2>/dev/null || echo "0")
          echo "æ¸…ç†è¿‡æœŸæ—¥å¿—: $DELETED_LOGS æ¡"

          # æ¸…ç†è¿‡æœŸçš„DNSè®°å½•æ“ä½œå†å²ï¼ˆä¿ç•™180å¤©ï¼‰
          DELETED_HISTORY=$(psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -t -c "DELETE FROM dns_record_history WHERE created_at < NOW() - INTERVAL '180 days' RETURNING 1;" | wc -l 2>/dev/null || echo "0")
          echo "æ¸…ç†è¿‡æœŸDNSå†å²: $DELETED_HISTORY æ¡"

          echo "âœ… è¿‡æœŸæ•°æ®æ¸…ç†å®Œæˆ"

      - name: ç´¢å¼•ä¼˜åŒ–
        env:
          PGPASSWORD: ${{ env.DB_PASSWORD }}
        run: |
          echo "æ£€æŸ¥ç´¢å¼•ä½¿ç”¨æƒ…å†µ..."

          # æŸ¥æ‰¾æœªä½¿ç”¨çš„ç´¢å¼•
          UNUSED_INDEXES=$(psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -t -c "
            SELECT schemaname||'.'||tablename||'.'||indexname as index_name
            FROM pg_stat_user_indexes 
            WHERE idx_scan = 0 AND schemaname = 'public'
            AND indexname NOT LIKE '%_pkey';" | tr -d ' ')

          if [ -n "$UNUSED_INDEXES" ]; then
            echo "å‘ç°æœªä½¿ç”¨çš„ç´¢å¼•:"
            echo "$UNUSED_INDEXES"
            
            # åœ¨éç”Ÿäº§ç¯å¢ƒåˆ é™¤æœªä½¿ç”¨çš„ç´¢å¼•
            if [ "$ENVIRONMENT" != "production" ]; then
              echo "$UNUSED_INDEXES" | while read -r index; do
                if [ -n "$index" ]; then
                  echo "åˆ é™¤æœªä½¿ç”¨ç´¢å¼•: $index"
                  psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -c "DROP INDEX IF EXISTS $index;"
                fi
              done
            fi
          else
            echo "âœ… æœªå‘ç°æœªä½¿ç”¨çš„ç´¢å¼•"
          fi

      - name: æ•°æ®åº“è†¨èƒ€æ£€æŸ¥
        env:
          PGPASSWORD: ${{ env.DB_PASSWORD }}
        run: |
          echo "æ£€æŸ¥è¡¨è†¨èƒ€æƒ…å†µ..."

          # æ£€æŸ¥è¡¨è†¨èƒ€
          psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -c "
            SELECT 
              schemaname,
              tablename,
              pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size,
              pg_size_pretty(pg_relation_size(schemaname||'.'||tablename)) as table_size
            FROM pg_tables 
            WHERE schemaname = 'public'
            ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC
            LIMIT 10;"

  # ===== æ·±åº¦ç»´æŠ¤ =====
  deep-maintenance:
    name: æ·±åº¦ç»´æŠ¤
    runs-on: ubuntu-latest
    needs: [pre-check, pre-maintenance-backup, routine-maintenance]
    if: always() && needs.pre-check.outputs.can-proceed == 'true' && (env.MAINTENANCE_TYPE == 'deep' || env.MAINTENANCE_TYPE == 'vacuum' || env.MAINTENANCE_TYPE == 'reindex')

    steps:
      - name: è®¾ç½®ç¯å¢ƒå˜é‡
        run: |
          if [ "$ENVIRONMENT" = "production" ]; then
            echo "DB_HOST=${{ secrets.PROD_DB_HOST }}" >> $GITHUB_ENV
            echo "DB_PORT=${{ secrets.PROD_DB_PORT }}" >> $GITHUB_ENV
            echo "DB_USER=${{ secrets.PROD_DB_USER }}" >> $GITHUB_ENV
            echo "DB_PASSWORD=${{ secrets.PROD_DB_PASSWORD }}" >> $GITHUB_ENV
            echo "DB_NAME=${{ secrets.PROD_DB_NAME }}" >> $GITHUB_ENV
          else
            echo "DB_HOST=${{ secrets.STAGING_DB_HOST }}" >> $GITHUB_ENV
            echo "DB_PORT=${{ secrets.STAGING_DB_PORT }}" >> $GITHUB_ENV
            echo "DB_USER=${{ secrets.STAGING_DB_USER }}" >> $GITHUB_ENV
            echo "DB_PASSWORD=${{ secrets.STAGING_DB_PASSWORD }}" >> $GITHUB_ENV
            echo "DB_NAME=${{ secrets.STAGING_DB_NAME }}" >> $GITHUB_ENV
          fi

      - name: å®‰è£…PostgreSQLå®¢æˆ·ç«¯
        run: |
          sudo apt-get update
          sudo apt-get install -y postgresql-client

      - name: VACUUM æ“ä½œ
        if: env.MAINTENANCE_TYPE == 'deep' || env.MAINTENANCE_TYPE == 'vacuum'
        env:
          PGPASSWORD: ${{ env.DB_PASSWORD }}
        run: |
          echo "æ‰§è¡ŒVACUUMæ“ä½œ..."

          # è·å–ä¸»è¦è¡¨åˆ—è¡¨
          TABLES=$(psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -t -c "SELECT tablename FROM pg_tables WHERE schemaname = 'public' ORDER BY tablename;")

          echo "å¼€å§‹VACUUMæ“ä½œ..."
          for table in $TABLES; do
            echo "VACUUMè¡¨: $table"
            if [ "$ENVIRONMENT" = "production" ]; then
              # ç”Ÿäº§ç¯å¢ƒä½¿ç”¨éé˜»å¡VACUUM
              psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -c "VACUUM (VERBOSE) $table;"
            else
              # éç”Ÿäº§ç¯å¢ƒå¯ä»¥ä½¿ç”¨VACUUM FULL
              psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -c "VACUUM FULL VERBOSE $table;"
            fi
          done

          echo "âœ… VACUUMæ“ä½œå®Œæˆ"

      - name: é‡å»ºç´¢å¼•
        if: env.MAINTENANCE_TYPE == 'deep' || env.MAINTENANCE_TYPE == 'reindex'
        env:
          PGPASSWORD: ${{ env.DB_PASSWORD }}
        run: |
          echo "é‡å»ºç´¢å¼•..."

          # è·å–éœ€è¦é‡å»ºçš„ç´¢å¼•
          INDEXES=$(psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -t -c "
            SELECT indexname 
            FROM pg_indexes 
            WHERE schemaname = 'public' 
            AND indexname NOT LIKE '%_pkey'
            ORDER BY indexname;")

          for index in $INDEXES; do
            if [ -n "$index" ] && [ "$index" != " " ]; then
              echo "é‡å»ºç´¢å¼•: $index"
              if [ "$ENVIRONMENT" = "production" ]; then
                # ç”Ÿäº§ç¯å¢ƒä½¿ç”¨CONCURRENTLYé‡å»º
                psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -c "REINDEX INDEX CONCURRENTLY $index;" || echo "ç´¢å¼• $index é‡å»ºå¤±è´¥"
              else
                psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -c "REINDEX INDEX $index;"
              fi
            fi
          done

          echo "âœ… ç´¢å¼•é‡å»ºå®Œæˆ"

      - name: æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
        env:
          PGPASSWORD: ${{ env.DB_PASSWORD }}
        run: |
          echo "æ£€æŸ¥æ•°æ®å®Œæ•´æ€§..."

          # æ£€æŸ¥å¤–é”®çº¦æŸ
          CONSTRAINT_VIOLATIONS=$(psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -t -c "
            SELECT COUNT(*) FROM (
              SELECT conname, conrelid::regclass, confrelid::regclass
              FROM pg_constraint
              WHERE contype = 'f'
            ) constraints;" | tr -d ' ')

          echo "å¤–é”®çº¦æŸæ•°é‡: $CONSTRAINT_VIOLATIONS"

          # æ£€æŸ¥è¡¨è¡Œæ•°ç»Ÿè®¡
          echo "ä¸»è¦è¡¨è¡Œæ•°ç»Ÿè®¡:"
          psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -c "
            SELECT 
              schemaname,
              tablename,
              n_tup_ins as inserts,
              n_tup_upd as updates,
              n_tup_del as deletes,
              n_live_tup as live_rows,
              n_dead_tup as dead_rows
            FROM pg_stat_user_tables 
            WHERE schemaname = 'public'
            ORDER BY n_live_tup DESC;"

  # ===== ç»´æŠ¤åæ£€æŸ¥ =====
  post-maintenance-check:
    name: ç»´æŠ¤åæ£€æŸ¥
    runs-on: ubuntu-latest
    needs: [pre-check, routine-maintenance, deep-maintenance]
    if: always() && needs.pre-check.outputs.can-proceed == 'true'

    steps:
      - name: è®¾ç½®ç¯å¢ƒå˜é‡
        run: |
          if [ "$ENVIRONMENT" = "production" ]; then
            echo "DB_HOST=${{ secrets.PROD_DB_HOST }}" >> $GITHUB_ENV
            echo "DB_PORT=${{ secrets.PROD_DB_PORT }}" >> $GITHUB_ENV
            echo "DB_USER=${{ secrets.PROD_DB_USER }}" >> $GITHUB_ENV
            echo "DB_PASSWORD=${{ secrets.PROD_DB_PASSWORD }}" >> $GITHUB_ENV
            echo "DB_NAME=${{ secrets.PROD_DB_NAME }}" >> $GITHUB_ENV
          else
            echo "DB_HOST=${{ secrets.STAGING_DB_HOST }}" >> $GITHUB_ENV
            echo "DB_PORT=${{ secrets.STAGING_DB_PORT }}" >> $GITHUB_ENV
            echo "DB_USER=${{ secrets.STAGING_DB_USER }}" >> $GITHUB_ENV
            echo "DB_PASSWORD=${{ secrets.STAGING_DB_PASSWORD }}" >> $GITHUB_ENV
            echo "DB_NAME=${{ secrets.STAGING_DB_NAME }}" >> $GITHUB_ENV
          fi

      - name: å®‰è£…PostgreSQLå®¢æˆ·ç«¯
        run: |
          sudo apt-get update
          sudo apt-get install -y postgresql-client

      - name: éªŒè¯æ•°æ®åº“çŠ¶æ€
        env:
          PGPASSWORD: ${{ env.DB_PASSWORD }}
        run: |
          echo "éªŒè¯æ•°æ®åº“çŠ¶æ€..."

          # æ£€æŸ¥æ•°æ®åº“è¿æ¥
          if psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -c "SELECT 1;" > /dev/null 2>&1; then
            echo "âœ… æ•°æ®åº“è¿æ¥æ­£å¸¸"
          else
            echo "âŒ æ•°æ®åº“è¿æ¥å¤±è´¥"
            exit 1
          fi

          # æ£€æŸ¥è¡¨å¯è®¿é—®æ€§
          TABLES_COUNT=$(psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -t -c "SELECT COUNT(*) FROM information_schema.tables WHERE table_schema = 'public';" | tr -d ' ')
          echo "å¯è®¿é—®è¡¨æ•°é‡: $TABLES_COUNT"

          # æ£€æŸ¥ç´¢å¼•çŠ¶æ€
          INDEXES_COUNT=$(psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -t -c "SELECT COUNT(*) FROM pg_indexes WHERE schemaname = 'public';" | tr -d ' ')
          echo "ç´¢å¼•æ•°é‡: $INDEXES_COUNT"

          # æ£€æŸ¥ç»´æŠ¤åçš„æ•°æ®åº“å¤§å°
          NEW_DB_SIZE=$(psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -t -c "SELECT pg_size_pretty(pg_database_size('$DB_NAME'));" | tr -d ' ')
          echo "ç»´æŠ¤åæ•°æ®åº“å¤§å°: $NEW_DB_SIZE"
          echo "ç»´æŠ¤å‰æ•°æ®åº“å¤§å°: ${{ needs.pre-check.outputs.db-size }}"

      - name: æ€§èƒ½æµ‹è¯•
        env:
          PGPASSWORD: ${{ env.DB_PASSWORD }}
        run: |
          echo "æ‰§è¡Œç»´æŠ¤åæ€§èƒ½æµ‹è¯•..."

          # ç®€å•æŸ¥è¯¢æ€§èƒ½æµ‹è¯•
          START_TIME=$(date +%s%N)
          psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -c "SELECT COUNT(*) FROM domains;" > /dev/null
          END_TIME=$(date +%s%N)
          QUERY_TIME=$(( (END_TIME - START_TIME) / 1000000 ))
          echo "åŸŸåè¡¨æŸ¥è¯¢æ—¶é—´: ${QUERY_TIME}ms"

          # ç´¢å¼•æŸ¥è¯¢æ€§èƒ½æµ‹è¯•
          START_TIME=$(date +%s%N)
          psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -c "SELECT * FROM domains WHERE user_id = 1 LIMIT 1;" > /dev/null
          END_TIME=$(date +%s%N)
          INDEX_QUERY_TIME=$(( (END_TIME - START_TIME) / 1000000 ))
          echo "ç´¢å¼•æŸ¥è¯¢æ—¶é—´: ${INDEX_QUERY_TIME}ms"

          if [ $QUERY_TIME -gt 1000 ]; then
            echo "âš ï¸ æŸ¥è¯¢æ€§èƒ½è¾ƒæ…¢"
          else
            echo "âœ… æŸ¥è¯¢æ€§èƒ½æ­£å¸¸"
          fi

  # ===== ç”Ÿæˆç»´æŠ¤æŠ¥å‘Š =====
  generate-maintenance-report:
    name: ç”Ÿæˆç»´æŠ¤æŠ¥å‘Š
    runs-on: ubuntu-latest
    needs:
      [pre-check, routine-maintenance, deep-maintenance, post-maintenance-check]
    if: always()

    steps:
      - name: ç”Ÿæˆç»´æŠ¤æŠ¥å‘Š
        run: |
          echo "# ğŸ”§ Database Maintenance Report" > maintenance-report.md
          echo "" >> maintenance-report.md
          echo "**ç»´æŠ¤æ—¶é—´**: $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> maintenance-report.md
          echo "**ç¯å¢ƒ**: $ENVIRONMENT" >> maintenance-report.md
          echo "**ç»´æŠ¤ç±»å‹**: $MAINTENANCE_TYPE" >> maintenance-report.md
          echo "**è·³è¿‡å¤‡ä»½**: $SKIP_BACKUP" >> maintenance-report.md
          echo "" >> maintenance-report.md

          echo "## ğŸ“‹ ç»´æŠ¤æ‰§è¡ŒçŠ¶æ€" >> maintenance-report.md
          echo "" >> maintenance-report.md
          echo "| ç»´æŠ¤é¡¹ç›® | çŠ¶æ€ | è¯´æ˜ |" >> maintenance-report.md
          echo "|---------|------|------|" >> maintenance-report.md
          echo "| é¢„æ£€æŸ¥ | ${{ needs.pre-check.result == 'success' && 'âœ… é€šè¿‡' || 'âŒ å¤±è´¥' }} | ç»´æŠ¤å‰ç¯å¢ƒæ£€æŸ¥ |" >> maintenance-report.md
          echo "| å¤‡ä»½ | ${{ needs.pre-maintenance-backup.result == 'success' && 'âœ… å®Œæˆ' || needs.pre-maintenance-backup.result == 'skipped' && 'â­ï¸ è·³è¿‡' || 'âŒ å¤±è´¥' }} | ç»´æŠ¤å‰æ•°æ®å¤‡ä»½ |" >> maintenance-report.md
          echo "| å¸¸è§„ç»´æŠ¤ | ${{ needs.routine-maintenance.result == 'success' && 'âœ… å®Œæˆ' || needs.routine-maintenance.result == 'skipped' && 'â­ï¸ è·³è¿‡' || 'âŒ å¤±è´¥' }} | ç»Ÿè®¡æ›´æ–°ã€æ•°æ®æ¸…ç† |" >> maintenance-report.md
          echo "| æ·±åº¦ç»´æŠ¤ | ${{ needs.deep-maintenance.result == 'success' && 'âœ… å®Œæˆ' || needs.deep-maintenance.result == 'skipped' && 'â­ï¸ è·³è¿‡' || 'âŒ å¤±è´¥' }} | VACUUMã€é‡å»ºç´¢å¼• |" >> maintenance-report.md
          echo "| åæ£€æŸ¥ | ${{ needs.post-maintenance-check.result == 'success' && 'âœ… é€šè¿‡' || 'âŒ å¤±è´¥' }} | ç»´æŠ¤åçŠ¶æ€éªŒè¯ |" >> maintenance-report.md
          echo "" >> maintenance-report.md

          echo "## ğŸ“Š æ•°æ®åº“çŠ¶æ€" >> maintenance-report.md
          echo "" >> maintenance-report.md
          echo "- **ç»´æŠ¤å‰å¤§å°**: ${{ needs.pre-check.outputs.db-size }}" >> maintenance-report.md
          echo "- **æ´»è·ƒè¿æ¥æ•°**: ${{ needs.pre-check.outputs.active-connections }}" >> maintenance-report.md
          echo "- **å¤‡ä»½æ–‡ä»¶**: ${{ needs.pre-maintenance-backup.outputs.backup-file || 'æœªåˆ›å»º' }}" >> maintenance-report.md
          echo "" >> maintenance-report.md

          # ç»´æŠ¤ç»“æœæ‘˜è¦
          OVERALL_SUCCESS="true"
          if [ "${{ needs.pre-check.result }}" != "success" ]; then
            OVERALL_SUCCESS="false"
          fi
          if [ "${{ needs.routine-maintenance.result }}" = "failure" ]; then
            OVERALL_SUCCESS="false"
          fi
          if [ "${{ needs.deep-maintenance.result }}" = "failure" ]; then
            OVERALL_SUCCESS="false"
          fi
          if [ "${{ needs.post-maintenance-check.result }}" != "success" ]; then
            OVERALL_SUCCESS="false"
          fi

          echo "## ğŸ“ˆ ç»´æŠ¤ç»“æœ" >> maintenance-report.md
          echo "" >> maintenance-report.md
          if [ "$OVERALL_SUCCESS" = "true" ]; then
            echo "ğŸŸ¢ **ç»´æŠ¤çŠ¶æ€**: æˆåŠŸå®Œæˆ" >> maintenance-report.md
            echo "" >> maintenance-report.md
            echo "âœ… æ‰€æœ‰ç»´æŠ¤ä»»åŠ¡å·²æˆåŠŸæ‰§è¡Œ" >> maintenance-report.md
            echo "âœ… æ•°æ®åº“çŠ¶æ€æ­£å¸¸" >> maintenance-report.md
            echo "âœ… æ€§èƒ½æ£€æŸ¥é€šè¿‡" >> maintenance-report.md
          else
            echo "ğŸ”´ **ç»´æŠ¤çŠ¶æ€**: éƒ¨åˆ†å¤±è´¥" >> maintenance-report.md
            echo "" >> maintenance-report.md
            echo "âš ï¸ éƒ¨åˆ†ç»´æŠ¤ä»»åŠ¡æ‰§è¡Œå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—" >> maintenance-report.md
            echo "âš ï¸ å»ºè®®æ‰‹åŠ¨éªŒè¯æ•°æ®åº“çŠ¶æ€" >> maintenance-report.md
          fi
          echo "" >> maintenance-report.md

          echo "## ğŸ”„ ä¸‹æ¬¡ç»´æŠ¤å»ºè®®" >> maintenance-report.md
          echo "" >> maintenance-report.md
          echo "- **å¸¸è§„ç»´æŠ¤**: æ¯æ—¥è‡ªåŠ¨æ‰§è¡Œ" >> maintenance-report.md
          echo "- **æ·±åº¦ç»´æŠ¤**: æ¯å‘¨æ‰§è¡Œ" >> maintenance-report.md
          echo "- **ç´§æ€¥ç»´æŠ¤**: æ ¹æ®ç›‘æ§å‘Šè­¦æŒ‰éœ€æ‰§è¡Œ" >> maintenance-report.md
          echo "" >> maintenance-report.md
          echo "---" >> maintenance-report.md
          echo "*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: $(date -u '+%Y-%m-%d %H:%M:%S UTC')*" >> maintenance-report.md

      - name: ä¸Šä¼ ç»´æŠ¤æŠ¥å‘Š
        uses: actions/upload-artifact@v3
        with:
          name: maintenance-report-${{ env.ENVIRONMENT }}
          path: maintenance-report.md

      - name: å‘é€ç»´æŠ¤é€šçŸ¥
        if: env.ENVIRONMENT == 'production' && secrets.SLACK_WEBHOOK_URL
        uses: 8398a7/action-slack@v3
        with:
          status: custom
          custom_payload: |
            {
              "text": "ğŸ”§ Domain MAX æ•°æ®åº“ç»´æŠ¤å®Œæˆ",
              "attachments": [
                {
                  "color": "${{ (needs.pre-check.result == 'success' && (needs.routine-maintenance.result == 'success' || needs.routine-maintenance.result == 'skipped') && (needs.deep-maintenance.result == 'success' || needs.deep-maintenance.result == 'skipped') && needs.post-maintenance-check.result == 'success') && 'good' || 'danger' }}",
                  "fields": [
                    {
                      "title": "ç¯å¢ƒ",
                      "value": "${{ env.ENVIRONMENT }}",
                      "short": true
                    },
                    {
                      "title": "ç»´æŠ¤ç±»å‹",
                      "value": "${{ env.MAINTENANCE_TYPE }}",
                      "short": true
                    },
                    {
                      "title": "æ•°æ®åº“å¤§å°",
                      "value": "${{ needs.pre-check.outputs.db-size }}",
                      "short": true
                    },
                    {
                      "title": "ç»´æŠ¤çŠ¶æ€",
                      "value": "${{ (needs.pre-check.result == 'success' && (needs.routine-maintenance.result == 'success' || needs.routine-maintenance.result == 'skipped') && (needs.deep-maintenance.result == 'success' || needs.deep-maintenance.result == 'skipped') && needs.post-maintenance-check.result == 'success') && 'æˆåŠŸ' || 'éƒ¨åˆ†å¤±è´¥' }}",
                      "short": true
                    }
                  ]
                }
              ]
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
